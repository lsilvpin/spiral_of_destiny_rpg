import http.client, json
from main.libraries.utils.core.settings_helper import get, load_environment


from main.libraries.tools.core.log_tool import LogTool
from main.libraries.tools.core.settings_tool import SettingsTool


class RoleInterpreter:
    """
    The RoleInterpreter class is responsible for interpreting roles and handling role-specific settings.

    Attributes:
        __role (str): The current role being interpreted.
    """

    __role: str

    def __init__(self, settings_tool: SettingsTool, logger: LogTool):
        """
        Initializes a new instance of the RoleInterpreter class.

        Args:
            settings_tool (SettingsTool): An instance of the SettingsTool class.
            logger (LogTool): An instance of the LogTool class.
        """
        self.settings_tool = settings_tool
        self.logger = logger

    def load(self, role: str) -> None:
        """
        Loads the settings for the specified role.

        Args:
            role (str): The role to load settings for.
        """
        self.logger.info(f"Loading {role} settings...")
        self.__role = role

    def get_role(self) -> str:
        """
        Gets the current role being interpreted.

        Returns:
            str: The current role being interpreted.
        """
        return self.__role

    def prompt(self, msg: str) -> str:
        """
        Prompts the user with a message and returns the response generated by the AI model.

        Args:
            msg (str): The message to prompt the user with.

        Returns:
            str: The response generated by the AI model.
        """
        org_id = self.settings_tool.get("OPENAI_ORG_ID")
        api_key = self.settings_tool.get("OPENAI_API_KEY")
        assert org_id is not None
        assert api_key is not None
        promptMsg = (
            f"Assuma que você é o {self.__role}. Use no máximo 30 palávras. {msg}"
        )
        payload = self.__build_payload_for_openai_chat_request(promptMsg)
        headers = self.__build_headers_for_openai_chat_request(api_key)
        conn = http.client.HTTPSConnection("api.openai.com")
        conn.request("POST", "/v1/chat/completions", payload, headers)
        res = conn.getresponse()
        data = res.read()
        resultJson = data.decode("utf-8")
        assert resultJson is not None
        result = json.loads(resultJson)
        self.__validate_ok_response(res, result)
        self.__log_usage(result)
        return result.get("choices")[0].get("message").get("content")

    def __log_usage(self, result):
        """
        Logs the usage statistics of the OpenAI API.

        Args:
            result (dict): The response received from the OpenAI API.
        """
        usage = result.get("usage")
        total_tokens = usage.get('total_tokens')
        tokens_per_message = usage.get('tokens_per_message')
        prompt_tokens = usage.get('prompt_tokens')
        self.logger.info(f"OpenAI usage: {total_tokens} tokens used")
        self.logger.info(f"{tokens_per_message} tokens per message")
        self.logger.info(f"{prompt_tokens} tokens used for prompt")

    def __validate_ok_response(self, res, result):
        """
        Validates the response received from the OpenAI API.

        Args:
            res: The HTTP response received from the OpenAI API.
            result (dict): The response received from the OpenAI API.

        Raises:
            Exception: If the response status is not 200.
        """
        if res.status != 200:
            self.logger.error(
                f"Failed to get response from OpenAI: {result.get('error')}"
            )
            raise Exception(
                f"Failed to get response from OpenAI: {result.get('error')}"
            )

    def __build_headers_for_openai_chat_request(self, api_key):
        """
        Builds the headers for the OpenAI chat request.

        Args:
            api_key (str): The API key for the OpenAI API.

        Returns:
            dict: The headers for the OpenAI chat request.
        """
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }
        return headers

    def __build_payload_for_openai_chat_request(self, promptMsg):
        """
        Builds the payload for the OpenAI chat request.

        Args:
            promptMsg (str): The message to prompt the user with.

        Returns:
            str: The payload for the OpenAI chat request.
        """
        payload = json.dumps(
            {
                "model": "gpt-3.5-turbo",
                "max_tokens": 50,
                "messages": [
                    {
                        "role": "user",
                        "content": promptMsg,
                    }
                ],
            }
        )
        return payload
